{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = [1, 2, 3]\n",
    "y_data = [1, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.random_uniform([1], -1.0, 1.0))\n",
    "b = tf.Variable(tf.random_uniform([1], -1.0, 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, name='X')\n",
    "Y = tf.placeholder(tf.float32, name='Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyprothesis = W * X + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.square(hyprothesis - Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "opimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "train_op = opimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 14.213638 [0.82071877] [0.84068865]\n",
      "1 0.25387356 [0.65177244] [0.7442634]\n",
      "2 0.083127275 [0.6790795] [0.73470175]\n",
      "3 0.07728308 [0.68472457] [0.7161296]\n",
      "4 0.073589444 [0.6925298] [0.6990139]\n",
      "5 0.070093594 [0.6998964] [0.6821992]\n",
      "6 0.06676411 [0.7071134] [0.6658008]\n",
      "7 0.06359278 [0.7141539] [0.6497953]\n",
      "8 0.06057207 [0.72102547] [0.63417464]\n",
      "9 0.057694856 [0.7277319] [0.61892956]\n",
      "10 0.054954316 [0.73427695] [0.6040509]\n",
      "11 0.05234396 [0.7406648] [0.58952993]\n",
      "12 0.049857557 [0.746899] [0.57535803]\n",
      "13 0.047489334 [0.7529834] [0.56152683]\n",
      "14 0.04523353 [0.7589215] [0.5480281]\n",
      "15 0.04308493 [0.76471686] [0.5348539]\n",
      "16 0.041038338 [0.77037287] [0.5219963]\n",
      "17 0.039088972 [0.77589303] [0.50944793]\n",
      "18 0.037232216 [0.78128034] [0.4972011]\n",
      "19 0.035463654 [0.78653824] [0.48524874]\n",
      "20 0.033779085 [0.79166967] [0.4735837]\n",
      "21 0.032174565 [0.7966778] [0.4621991]\n",
      "22 0.030646281 [0.8015655] [0.45108813]\n",
      "23 0.029190542 [0.8063358] [0.4402443]\n",
      "24 0.027803995 [0.8109914] [0.42966112]\n",
      "25 0.02648326 [0.81553495] [0.41933233]\n",
      "26 0.025225312 [0.8199694] [0.4092519]\n",
      "27 0.024027072 [0.8242972] [0.39941373]\n",
      "28 0.022885755 [0.82852095] [0.3898121]\n",
      "29 0.02179868 [0.8326433] [0.38044134]\n",
      "30 0.020763213 [0.83666635] [0.37129575]\n",
      "31 0.019776948 [0.8405928] [0.36237007]\n",
      "32 0.018837543 [0.84442484] [0.35365894]\n",
      "33 0.017942725 [0.84816474] [0.3451572]\n",
      "34 0.017090455 [0.8518148] [0.33685988]\n",
      "35 0.016278623 [0.855377] [0.32876197]\n",
      "36 0.015505377 [0.85885364] [0.32085875]\n",
      "37 0.014768872 [0.86224675] [0.31314552]\n",
      "38 0.014067345 [0.86555827] [0.30561772]\n",
      "39 0.01339911 [0.8687901] [0.29827085]\n",
      "40 0.012762657 [0.8719443] [0.29110065]\n",
      "41 0.012156423 [0.8750227] [0.2841028]\n",
      "42 0.011578978 [0.878027] [0.27727315]\n",
      "43 0.011028963 [0.8809592] [0.2706077]\n",
      "44 0.010505095 [0.8838209] [0.2641025]\n",
      "45 0.010006093 [0.8866138] [0.25775364]\n",
      "46 0.0095308 [0.88933945] [0.2515574]\n",
      "47 0.00907807 [0.89199966] [0.24551016]\n",
      "48 0.008646865 [0.8945959] [0.23960827]\n",
      "49 0.008236117 [0.8971298] [0.23384826]\n",
      "50 0.007844898 [0.89960265] [0.22822669]\n",
      "51 0.007472264 [0.90201616] [0.22274029]\n",
      "52 0.0071173315 [0.9043717] [0.21738578]\n",
      "53 0.0067792586 [0.90667045] [0.21215995]\n",
      "54 0.006457241 [0.9089141] [0.20705979]\n",
      "55 0.006150501 [0.91110367] [0.20208219]\n",
      "56 0.0058583603 [0.91324073] [0.19722427]\n",
      "57 0.005580072 [0.9153263] [0.19248311]\n",
      "58 0.0053150184 [0.91736186] [0.18785597]\n",
      "59 0.005062545 [0.91934836] [0.18334003]\n",
      "60 0.0048220735 [0.9212872] [0.17893267]\n",
      "61 0.00459302 [0.9231794] [0.17463125]\n",
      "62 0.004374849 [0.9250261] [0.17043324]\n",
      "63 0.004167042 [0.92682844] [0.16633615]\n",
      "64 0.0039691054 [0.92858744] [0.16233754]\n",
      "65 0.00378057 [0.93030417] [0.15843506]\n",
      "66 0.0036009878 [0.93197954] [0.15462637]\n",
      "67 0.0034299449 [0.9336148] [0.15090929]\n",
      "68 0.003267015 [0.9352106] [0.14728153]\n",
      "69 0.0031118297 [0.9367681] [0.143741]\n",
      "70 0.002964016 [0.93828815] [0.14028555]\n",
      "71 0.002823228 [0.93977165] [0.13691318]\n",
      "72 0.0026891164 [0.94121945] [0.13362187]\n",
      "73 0.0025613762 [0.9426325] [0.1304097]\n",
      "74 0.002439711 [0.9440116] [0.12727477]\n",
      "75 0.002323833 [0.94535756] [0.12421516]\n",
      "76 0.002213443 [0.9466711] [0.1212291]\n",
      "77 0.002108297 [0.94795305] [0.11831482]\n",
      "78 0.002008158 [0.94920427] [0.11547063]\n",
      "79 0.0019127643 [0.9504254] [0.11269481]\n",
      "80 0.0018219141 [0.9516171] [0.10998569]\n",
      "81 0.0017353735 [0.95278025] [0.10734173]\n",
      "82 0.0016529383 [0.9539153] [0.10476128]\n",
      "83 0.0015744219 [0.95502317] [0.1022429]\n",
      "84 0.0014996392 [0.9561044] [0.09978505]\n",
      "85 0.0014284 [0.9571596] [0.09738626]\n",
      "86 0.0013605492 [0.9581894] [0.09504516]\n",
      "87 0.0012959267 [0.9591946] [0.09276037]\n",
      "88 0.0012343698 [0.9601755] [0.09053046]\n",
      "89 0.0011757318 [0.9611329] [0.08835417]\n",
      "90 0.0011198898 [0.96206725] [0.0862302]\n",
      "91 0.0010666851 [0.962979] [0.08415724]\n",
      "92 0.0010160244 [0.96386904] [0.08213418]\n",
      "93 0.0009677589 [0.9647376] [0.08015973]\n",
      "94 0.0009217921 [0.9655853] [0.07823275]\n",
      "95 0.0008780009 [0.9664126] [0.07635209]\n",
      "96 0.00083629537 [0.96722] [0.07451663]\n",
      "97 0.00079657504 [0.96800804] [0.07272531]\n",
      "98 0.0007587353 [0.96877706] [0.07097703]\n",
      "99 0.00072269916 [0.9695277] [0.06927081]\n",
      "X: 5, Y: [4.916909]\n",
      "X: 2.5, Y: [2.4930902]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(100):\n",
    "        _, cost_val = sess.run([train_op, cost], feed_dict={X: x_data, Y: y_data})\n",
    "        print(step, cost_val, sess.run(W), sess.run(b))\n",
    "    \n",
    "    print(\"X: 5, Y:\", sess.run(hyprothesis, feed_dict={X: 5}))\n",
    "    print(\"X: 2.5, Y:\", sess.run(hyprothesis, feed_dict={X: 2.5}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
